{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88a4e30a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device name: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import collections\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "import torch.autograd as autograd\n",
    "import random\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device name:',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f0682a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_new.cpp:201.)\n"
     ]
    }
   ],
   "source": [
    "## Data load ##\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file_path = 'ff5_filtered_XY_data_18980_to_19000_0.2s_intervals.csv'\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Set agent list (e.g., from A to N)\n",
    "agents = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N']\n",
    "valid_agents = [agent for agent in agents if f'X(m)_{agent}' in data.columns and f'Y(m)_{agent}' in data.columns]\n",
    "\n",
    "# Convert t(s) data to tensor\n",
    "t_tensor = torch.tensor(data['t(s)'].values, dtype=torch.float32).to(device)\n",
    "\n",
    "# Lists to store X, Y, dX/dt, dY/dt data (prepared to make 2D tensors for each)\n",
    "X_data, Y_data, dX_data, dY_data = [], [], [], []\n",
    "\n",
    "# Add X, Y, dX/dt, dY/dt data to the list for each agent\n",
    "for agent in agents:\n",
    "    if f'X(m)_{agent}' in data.columns and f'Y(m)_{agent}' in data.columns:\n",
    "        X_data.append(data[f'X(m)_{agent}'].values)\n",
    "        Y_data.append(data[f'Y(m)_{agent}'].values)\n",
    "    if f'dX/dt(m/s)_{agent}' in data.columns and f'dY/dt(m/s)_{agent}' in data.columns:\n",
    "        dX_data.append(data[f'dX/dt(m/s)_{agent}'].values)\n",
    "        dY_data.append(data[f'dY/dt(m/s)_{agent}'].values)\n",
    "\n",
    "# Convert the list to tensor (convert each to a 2D tensor, rows represent time, columns represent agents)\n",
    "X_tensor = torch.tensor(X_data, dtype=torch.float32).T.to(device)  # transpose to match shape [time, agents]\n",
    "Y_tensor = torch.tensor(Y_data, dtype=torch.float32).T.to(device)\n",
    "dX_tensor = torch.tensor(dX_data, dtype=torch.float32).T.to(device)\n",
    "dY_tensor = torch.tensor(dY_data, dtype=torch.float32).T.to(device)\n",
    "\n",
    "t_tensor = (t_tensor - t_tensor[0]).reshape(len(t_tensor), 1)\n",
    "X_tensor = X_tensor - torch.mean(X_tensor)\n",
    "Y_tensor = Y_tensor - torch.mean(Y_tensor)\n",
    "\n",
    "# Group tensors into a dictionary\n",
    "tensor_dict = {\n",
    "    't': t_tensor,\n",
    "    'X': X_tensor,\n",
    "    'Y': Y_tensor,\n",
    "    'dX/dt': dX_tensor,\n",
    "    'dY/dt': dY_tensor\n",
    "}\n",
    "\n",
    "v0_mean = torch.mean(torch.sqrt(dX_tensor**2 + dY_tensor**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3630b5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = torch.finfo(torch.float32).eps\n",
    "\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self, input_num, output_num, receivers, senders, radius, bias=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bias=bias\n",
    "        self.radius_tg = radius\n",
    "        self.fc1 = nn.Linear(input_num,32, bias=bias)\n",
    "        self.fc2 = nn.Linear(32,32, bias=bias)\n",
    "        self.fc3 = nn.Linear(32,32, bias=bias)\n",
    "        self.fc4 = nn.Linear(32, output_num, bias=bias)\n",
    "        self.reset_parameters()\n",
    "        \n",
    "        self.receivers=receivers\n",
    "        self.senders=senders\n",
    "        \n",
    "        self.ang_threshold = torch.tensor([torch.pi*2]).requires_grad_(True).to(device)\n",
    "        self.ang_threshold = nn.Parameter(self.ang_threshold)\n",
    "        \n",
    "        self.lambda1 = torch.FloatTensor(1).uniform_(-0.1, 0.1).requires_grad_(True).to(device)\n",
    "        self.lambda2 = torch.FloatTensor(1).uniform_(-0.1, 0.1).requires_grad_(True).to(device)\n",
    "        self.lambda3 = torch.FloatTensor(1).uniform_(-0.1, 0.1).requires_grad_(True).to(device)  \n",
    "        self.lambda4 = torch.FloatTensor(1).uniform_(-0.1, 0.1).requires_grad_(True).to(device)\n",
    "        self.power1 = torch.FloatTensor(1).uniform_(-0.1, 0.1).requires_grad_(True).to(device)\n",
    "        self.power2 = torch.FloatTensor(1).uniform_(-0.1, 0.1).requires_grad_(True).to(device)\n",
    "        self.power3 = torch.FloatTensor(1).uniform_(-0.1, 0.1).requires_grad_(True).to(device)\n",
    "        \n",
    "        self.lambda1 = nn.Parameter(self.lambda1)\n",
    "        self.lambda2 = nn.Parameter(self.lambda2)\n",
    "        self.lambda3 = nn.Parameter(self.lambda3)\n",
    "        self.lambda4 = nn.Parameter(self.lambda4)\n",
    "        self.power1 = nn.Parameter(self.power1)\n",
    "        self.power2 = nn.Parameter(self.power2)\n",
    "        self.power3 = nn.Parameter(self.power3)\n",
    "        \n",
    "        self.lambda1_v = torch.FloatTensor(1).uniform_(-0.1, 0.1).requires_grad_(True).to(device)\n",
    "        self.lambda2_v = torch.FloatTensor(1).uniform_(-0.1, 0.1).requires_grad_(True).to(device)\n",
    "        self.lambda3_v = torch.FloatTensor(1).uniform_(-0.1, 0.1).requires_grad_(True).to(device)\n",
    "        self.lambda4_v = torch.FloatTensor(1).uniform_(-0.1, 0.1).requires_grad_(True).to(device)\n",
    "        self.power1_v = torch.FloatTensor(1).uniform_(-0.1, 0.1).requires_grad_(True).to(device) \n",
    "        self.power2_v = torch.FloatTensor(1).uniform_(-0.1, 0.1).requires_grad_(True).to(device)\n",
    "        self.power3_v = torch.FloatTensor(1).uniform_(-0.1, 0.1).requires_grad_(True).to(device)\n",
    "\n",
    "        self.lambda1_v = nn.Parameter(self.lambda1_v)\n",
    "        self.lambda2_v = nn.Parameter(self.lambda2_v)\n",
    "        self.lambda3_v = nn.Parameter(self.lambda3_v)\n",
    "        self.lambda4_v = nn.Parameter(self.lambda4_v)\n",
    "        self.power1_v = nn.Parameter(self.power1_v)\n",
    "        self.power2_v = nn.Parameter(self.power2_v)\n",
    "        self.power3_v = nn.Parameter(self.power3_v)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.input = x\n",
    "        self.row_num = x.size(0)\n",
    "        x_max = x[-1].item()//2\n",
    "        \n",
    "        x=(self.input-x_max)/x_max\n",
    "        self.x1=torch.tanh(self.fc1(x))\n",
    "        self.x2=torch.tanh(self.fc2(self.x1))\n",
    "        self.x3=torch.tanh(self.fc3(self.x2))\n",
    "        self.x4 = self.fc4(self.x3)\n",
    "        output =radius*self.x4\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        nn.init.xavier_uniform_(self.fc1.weight, gain = nn.init.calculate_gain('tanh'))\n",
    "        nn.init.xavier_uniform_(self.fc2.weight, gain = nn.init.calculate_gain('tanh'))\n",
    "        nn.init.xavier_uniform_(self.fc3.weight, gain = nn.init.calculate_gain('tanh'))\n",
    "        nn.init.xavier_uniform_(self.fc4.weight, gain=1)\n",
    "        \n",
    "        if self.bias:\n",
    "            nn.init.constant_(self.fc1.bias, 0.1)\n",
    "            nn.init.constant_(self.fc2.bias, 0.1)\n",
    "            nn.init.constant_(self.fc3.bias, 0.1)\n",
    "            nn.init.constant_(self.fc4.bias, 0.1)\n",
    "            \n",
    "    def loss_func(self, pred, data, v0, radius=2):\n",
    "        #calculate gradients\n",
    "        \n",
    "        num_agents = data['X'].shape[1]\n",
    "        loss_mse = nn.MSELoss().to(device)\n",
    "        \n",
    "        for i in range(pred.size(1)):\n",
    "            temp=torch.zeros_like(pred)\n",
    "            temp[:,i]=1\n",
    "            grads, = autograd.grad(pred, self.input, grad_outputs=temp, create_graph=True)\n",
    "            if i==0:\n",
    "                self.u = grads\n",
    "            else:\n",
    "                self.u = torch.hstack((self.u, grads))\n",
    "\n",
    "        self.u_mag=torch.sqrt(torch.square(self.u[:,0:num_agents])+torch.square(self.u[:,num_agents:]))\n",
    "\n",
    "        for i in range(pred.size(1)):\n",
    "            temp=torch.zeros_like(pred)\n",
    "            temp[:,i]=1\n",
    "            grads, = autograd.grad(self.u, self.input, grad_outputs=temp, create_graph=True)\n",
    "            if i==0:\n",
    "                self.accel = grads\n",
    "            else:\n",
    "                self.accel = torch.hstack((self.accel, grads))\n",
    "        \n",
    "        N_time=pred.size(0)\n",
    "        \n",
    "        \n",
    "        ##### calculate distance #########\n",
    "\n",
    "        pos_x = pred[:,0:num_agents]\n",
    "        pos_y = pred[:,num_agents:]\n",
    "        pos_x_r = pos_x[:, self.receivers.flatten().type(torch.int64)]\n",
    "        pos_y_r = pos_y[:, self.receivers.flatten().type(torch.int64)]\n",
    "        pos_x_s = pos_x[:, self.senders.flatten().type(torch.int64)]\n",
    "        pos_y_s = pos_y[:, self.senders.flatten().type(torch.int64)]\n",
    "\n",
    "        dist_x = pos_x_r - pos_x_s\n",
    "        dist_y = pos_y_r - pos_y_s\n",
    "        dist = torch.sqrt(torch.square(dist_x)+torch.square(dist_y))\n",
    "        self.dist_value = dist.detach()\n",
    "        self.dist_max = torch.max(self.dist_value)\n",
    "\n",
    "        \n",
    "        ##### calculate relative velocity distance #########\n",
    "        \n",
    "        vel_x = self.u[:,0:num_agents]\n",
    "        vel_y = self.u[:,num_agents:]\n",
    "        vel_x_r = vel_x[:, self.receivers.flatten().type(torch.int64)]\n",
    "        vel_y_r = vel_y[:, self.receivers.flatten().type(torch.int64)]\n",
    "        vel_x_s = vel_x[:, self.senders.flatten().type(torch.int64)]\n",
    "        vel_y_s = vel_y[:, self.senders.flatten().type(torch.int64)]\n",
    "        \n",
    "        vel_rel_x = vel_x_r - vel_x_s\n",
    "        vel_rel_y = vel_y_r - vel_y_s\n",
    "        vel_rel = torch.sqrt(torch.square(vel_rel_x)+torch.square(vel_rel_y))\n",
    "        \n",
    "        u_x_r = self.u[:,self.receivers.flatten().type(torch.int64)]\n",
    "        u_y_r = self.u[:,num_agents + self.receivers.flatten().type(torch.int64)]\n",
    "        u_mag_r = torch.sqrt(torch.square(u_x_r)+torch.square(u_y_r))\n",
    "        \n",
    "        ### Define h(theta) ###\n",
    "        self.ang_interact = torch.atan2(u_y_r * (-dist_x) - u_x_r * (-dist_y), u_x_r * (-dist_x) + u_y_r * (-dist_y))\n",
    "        self.ang_eff = torch.exp(-self.ang_interact**2 / (2 * self.ang_threshold**2))\n",
    "        \n",
    "        ######## calculate loss between output edges and f_inter matgnitude from physics ######\n",
    "        self.f_inter_x=((dist_x/dist)*(self.lambda1*(dist**self.power1)+self.lambda2*(dist**self.power2)+\\\n",
    "                                       self.lambda3*(dist**self.power3)+self.lambda4) +\\\n",
    "                        (vel_rel_x/vel_rel)*(self.lambda1_v*(dist**self.power1_v) + self.lambda2_v*(dist**self.power2_v)+\\\n",
    "                                             self.lambda3_v*(dist**self.power3_v) + self.lambda4_v))*self.ang_eff\n",
    "        \n",
    "        self.f_inter_y=((dist_y/dist)*(self.lambda1*(dist**self.power1)+self.lambda2*(dist**self.power2)+\\\n",
    "                                       self.lambda3*(dist**self.power3)+self.lambda4) +\\\n",
    "                        (vel_rel_y/vel_rel)*(self.lambda1_v*(dist**self.power1_v) + self.lambda2_v*(dist**self.power2_v)+\\\n",
    "                                             self.lambda3_v*(dist**self.power3_v) + self.lambda4_v))*self.ang_eff\n",
    "        \n",
    "\n",
    "        f_agg_x = torch.zeros(self.row_num, num_agents).to(device)\n",
    "        f_agg_y = torch.zeros(self.row_num, num_agents).to(device)\n",
    "\n",
    "        f_agg_x = f_agg_x.scatter_add_(1, self.receivers.flatten().repeat(self.row_num,1).type(torch.int64), self.f_inter_x).to(device)\n",
    "        f_agg_y = f_agg_y.scatter_add_(1, self.receivers.flatten().repeat(self.row_num,1).type(torch.int64), self.f_inter_y).to(device)\n",
    "        \n",
    "        ######## Self propelled term #########        \n",
    "        \n",
    "        sp_x = 1*self.u[:,0:num_agents]*(v0/self.u_mag-1)\n",
    "        sp_y = 1*self.u[:,num_agents:]*(v0/self.u_mag-1)\n",
    "        \n",
    "        ode_x = self.accel[:,0:num_agents]-sp_x-f_agg_x\n",
    "        ode_y = self.accel[:,num_agents:]-sp_y-f_agg_y\n",
    "\n",
    "        self.loss_force = torch.sum(torch.square(ode_x[:,1:])+torch.square(ode_y[:,1:]))/(pred.size(0)*(num_agents-1)) #without agent A (i=0)\n",
    "        \n",
    "        \n",
    "        ########### Loss from data##########\n",
    "        self.loss_pos_x = loss_mse(pred[:, 0:num_agents], data['X'])\n",
    "        self.loss_pos_y = loss_mse(pred[:, num_agents:], data['Y'])\n",
    "        \n",
    "        loss = 5*self.loss_pos_x + 5*self.loss_pos_y + 1*self.loss_force\n",
    "   \n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "419055f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##ff5 receivers and senders ##\n",
    "## referred Nagy et al. Hierarchical group dynamics in pigeon flocks. Nature 464, 890–893 (2010).##\n",
    "\n",
    "interacting_agents =[\n",
    "    [0,0,0,0,0,0,0,0,0], ##A\n",
    "    [1,0,0,1,0,0,0,0,1], ##B\n",
    "    [1,1,1,1,1,1,0,1,1], ##C\n",
    "    [1,0,0,1,0,0,0,0,1], ##D\n",
    "    [1,0,0,0,0,0,0,0,1], ##G\n",
    "    [1,1,0,1,1,0,0,0,1], ##H\n",
    "    [1,1,0,1,1,0,0,0,1], ##I\n",
    "    [1,1,0,1,1,1,1,1,1], ##J\n",
    "    [1,1,0,1,1,0,0,0,1], ##L\n",
    "    [1,0,0,0,0,0,0,0,0], ##M\n",
    "]\n",
    "\n",
    "num_agents = X_tensor.shape[1]\n",
    "interacting_agents_G = torch.tensor(interacting_agents, dtype=torch.bool).to(device)\n",
    "\n",
    "senders=[]\n",
    "receivers=[]\n",
    "\n",
    "for i in range(num_agents):\n",
    "    for j in range(num_agents-1):\n",
    "        receivers.append([i])\n",
    "    for k in range(num_agents):\n",
    "        if k!=i:\n",
    "            senders.append([k])\n",
    "\n",
    "receivers_G= torch.tensor(receivers, dtype=torch.float32).to(device)  #index of the receiver node for edge\n",
    "receivers_G = receivers_G.reshape(num_agents,num_agents-1)[interacting_agents_G].reshape(-1,1)\n",
    "senders_G= torch.tensor(senders, dtype=torch.float32).to(device)  #index of the sender node for edge\n",
    "senders_G = senders_G.reshape(num_agents,num_agents-1)[interacting_agents_G].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c966fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure():\n",
    "    model.train()\n",
    "    optimizer_LBFGS.zero_grad()\n",
    "    pred=model(t)\n",
    "    loss=model.loss_func(pred, data=tensor_dict, v0 = v0_mean, radius=radius)\n",
    "\n",
    "    if torch.isfinite(loss).item:\n",
    "        loss.backward() \n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2d14181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Started\n",
      "Training Stopped\n",
      "#Distance coeff\n",
      "lambda1 = -7.428e-02 \n",
      "lambda2 = -2.368e-01 \n",
      "lambda3 = 1.169e+00 \n",
      "lambda4 = 9.349e-01\n",
      "power1 = 5.334e-01 \n",
      "power2 = 6.135e-01 \n",
      "power3 = -3.602e-01\n",
      "#Velocity coeff\n",
      "lambda1_v = -1.025e-01 \n",
      "lambda2_v = 3.151e-01 \n",
      "lambda3_v = 8.753e-02 \n",
      "lambda4_v = 8.356e-02\n",
      "power1_v = 7.021e-01 \n",
      "power2_v = 9.277e-02 \n",
      "power3_v = 2.413e-01\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#### define hyperparameter####\n",
    "\n",
    "\n",
    "epoch_adam=200\n",
    "epoch_LBFGS=1000\n",
    "patience=-21\n",
    "tolerance=1e-4\n",
    "\n",
    "#### define input ####\n",
    "t = tensor_dict['t'].requires_grad_(True)\n",
    "radius = torch.mean(torch.sqrt(tensor_dict['X']**2 + tensor_dict['Y']**2))\n",
    "num_agents = tensor_dict['X'].shape[1]\n",
    "out_num = num_agents*2\n",
    "\n",
    "retry_num = 100\n",
    "\n",
    "print(\"Training Started\")\n",
    "for ii in range(retry_num):\n",
    "    loss_value=[]\n",
    "    ##define model\n",
    "    model=PINN(input_num=1, output_num=out_num, receivers=receivers_G, senders=senders_G, radius = radius).to(device)\n",
    "\n",
    "\n",
    "    ## ADAM ##\n",
    "    for i in range(epoch_adam):\n",
    "        learning_rate = 0.001\n",
    "        optimizer_adam=torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        model.train()\n",
    "        optimizer_adam.zero_grad()\n",
    "\n",
    "        pred=model(t)\n",
    "        loss=model.loss_func(pred, data=tensor_dict, v0 = v0_mean, radius=radius)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer_adam.step()\n",
    "        loss_value.append(loss.item())\n",
    "\n",
    "        ### Early Stop condition ###\n",
    "        if i>21:\n",
    "            if loss_value[-1] <= loss_value[-2] and abs(loss_value[-1]-np.mean(loss_value[patience:-1])) < tolerance:\n",
    "                break\n",
    "\n",
    "\n",
    "    ##LBFGS ##\n",
    "    optimizer_LBFGS=torch.optim.LBFGS(model.parameters(), lr=0.1, max_iter=20, line_search_fn = 'strong_wolfe')\n",
    "\n",
    "    for i in range(epoch_LBFGS):\n",
    "\n",
    "        loss_prev = optimizer_LBFGS.step(closure)\n",
    "        if torch.isfinite(loss_prev) == False:\n",
    "            break\n",
    "\n",
    "        loss_value.append(loss_prev.item())\n",
    "        ### Early Stop condition ###\n",
    "        if i>21:\n",
    "            if loss_value[-1] <= loss_value[-2] and abs(loss_value[-1]-np.mean(loss_value[patience:-1])) < tolerance:\n",
    "                break\n",
    "\n",
    "    ### Stopping Condition ####\n",
    "    if model.loss_force.item()<10:\n",
    "        break\n",
    "            \n",
    "print(\"Training Stopped\")\n",
    "print('#Distance coeff')\n",
    "print(\"lambda1 = %.3e \\nlambda2 = %.3e \\nlambda3 = %.3e \\nlambda4 = %.3e\" \\\n",
    "      %(model.lambda1, model.lambda2, model.lambda3, model.lambda4))\n",
    "print(\"power1 = %.3e \\npower2 = %.3e \\npower3 = %.3e\" \\\n",
    "      %(model.power1, model.power2, model.power3))\n",
    "print('#Velocity coeff')\n",
    "print(\"lambda1_v = %.3e \\nlambda2_v = %.3e \\nlambda3_v = %.3e \\nlambda4_v = %.3e\" \\\n",
    "      %(model.lambda1_v, model.lambda2_v, model.lambda3_v, model.lambda4_v))\n",
    "print(\"power1_v = %.3e \\npower2_v = %.3e \\npower3_v = %.3e\" \\\n",
    "      %(model.power1_v, model.power2_v, model.power3_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33894c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
