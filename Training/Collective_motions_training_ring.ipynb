{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88a4e30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device name: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "import torch.autograd as autograd\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device name:',device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3630b5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Define class for neural network #####\n",
    "\n",
    "eps = torch.finfo(torch.float32).eps\n",
    "\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self, input_num, output_num, receivers, senders, radius, bias=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bias=bias\n",
    "        self.radius_tg = radius\n",
    "        self.fc1 = nn.Linear(input_num,32, bias=bias)\n",
    "        self.fc2 = nn.Linear(32,32, bias=bias)\n",
    "        self.fc3 = nn.Linear(32,32, bias=bias)\n",
    "        self.fc4 = nn.Linear(32, output_num, bias=bias)\n",
    "        self.reset_parameters()\n",
    "        \n",
    "        self.receivers=receivers\n",
    "        self.senders=senders\n",
    "\n",
    "        self.lambda1 = torch.FloatTensor(1).uniform_(-1, 1).requires_grad_(True).to(device)\n",
    "        self.lambda2 = torch.FloatTensor(1).uniform_(-1, 1).requires_grad_(True).to(device)\n",
    "        self.lambda3 = torch.FloatTensor(1).uniform_(-1, 1).requires_grad_(True).to(device)\n",
    "        self.lambda4 = torch.FloatTensor(1).uniform_(-1, 1).requires_grad_(True).to(device)\n",
    "        self.power1 = torch.FloatTensor(1).uniform_(-1, 1).requires_grad_(True).to(device)\n",
    "        self.power2 = torch.FloatTensor(1).uniform_(-1, 1).requires_grad_(True).to(device)\n",
    "        self.power3 = torch.FloatTensor(1).uniform_(-1, 1).requires_grad_(True).to(device)     \n",
    "        \n",
    "        self.lambda1 = nn.Parameter(self.lambda1)\n",
    "        self.lambda2 = nn.Parameter(self.lambda2)\n",
    "        self.lambda3 = nn.Parameter(self.lambda3)\n",
    "        self.lambda4 = nn.Parameter(self.lambda4)\n",
    "        self.power1 = nn.Parameter(self.power1)\n",
    "        self.power2 = nn.Parameter(self.power2)\n",
    "        self.power3 = nn.Parameter(self.power3)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.input = x\n",
    "        self.row_num = x.size(0)\n",
    "        x_max = x[-1].item()//2\n",
    "        \n",
    "        x=(self.input-x_max)/x_max\n",
    "        self.x1=torch.tanh(self.fc1(x))\n",
    "        self.x2=torch.tanh(self.fc2(self.x1))\n",
    "        self.x3=torch.tanh(self.fc3(self.x2))\n",
    "        self.x4 = self.fc4(self.x3)\n",
    "        output = self.radius_tg*self.x4\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        nn.init.xavier_uniform_(self.fc1.weight, gain = nn.init.calculate_gain('tanh'))\n",
    "        nn.init.xavier_uniform_(self.fc2.weight, gain = nn.init.calculate_gain('tanh'))\n",
    "        nn.init.xavier_uniform_(self.fc3.weight, gain = nn.init.calculate_gain('tanh'))\n",
    "        nn.init.xavier_uniform_(self.fc4.weight, gain=1)\n",
    "        \n",
    "        if self.bias:\n",
    "            nn.init.constant_(self.fc1.bias, 0.1)\n",
    "            nn.init.constant_(self.fc2.bias, 0.1)\n",
    "            nn.init.constant_(self.fc3.bias, 0.1)\n",
    "            nn.init.constant_(self.fc4.bias, 0.1)\n",
    "            \n",
    "    def loss_func(self, pred, r_a=1.0, r_b=4.0, v0=2, tau=10):\n",
    "        loss_mse = nn.MSELoss().to(device)\n",
    "        #calculate gradients\n",
    "        \n",
    "        half = pred.size(1)//2\n",
    "        radius = (r_a+r_b)/2\n",
    "        \n",
    "        center_x = torch.mean(pred[:,0:half], dim=1, keepdim=True)\n",
    "        center_y = torch.mean(pred[:,half:], dim=1, keepdim=True)\n",
    "        \n",
    "        for i in range(pred.size(1)):\n",
    "            temp=torch.zeros_like(pred)\n",
    "            temp[:,i]=1\n",
    "            grads, = autograd.grad(pred, self.input, grad_outputs=temp, create_graph=True)\n",
    "            if i==0:\n",
    "                self.u = grads\n",
    "            else:\n",
    "                self.u = torch.hstack((self.u, grads))\n",
    "\n",
    "        self.u_mag=torch.sqrt(torch.square(self.u[:,0:half])+torch.square(self.u[:,half:]))\n",
    "\n",
    "        for i in range(pred.size(1)):\n",
    "            temp=torch.zeros_like(pred)\n",
    "            temp[:,i]=1\n",
    "            grads, = autograd.grad(self.u, self.input, grad_outputs=temp, create_graph=True)\n",
    "            if i==0:\n",
    "                self.accel = grads\n",
    "            else:\n",
    "                self.accel = torch.hstack((self.accel, grads))\n",
    "        \n",
    "        N_time=pred.size(0)\n",
    "        \n",
    "        \n",
    "        #calculate loss between output edges and f_inter matgnitude from physics\n",
    "\n",
    "        pos_x = pred[:,0:half]\n",
    "        pos_y = pred[:,half:]\n",
    "        pos_x_r = pos_x[:, self.receivers.flatten().type(torch.int64)]\n",
    "        pos_y_r = pos_y[:, self.receivers.flatten().type(torch.int64)]\n",
    "        pos_x_s = pos_x[:, self.senders.flatten().type(torch.int64)]\n",
    "        pos_y_s = pos_y[:, self.senders.flatten().type(torch.int64)]\n",
    "\n",
    "        dist_x = pos_x_r - pos_x_s\n",
    "        dist_y = pos_y_r - pos_y_s\n",
    "        dist=torch.sqrt(torch.square(dist_x)+torch.square(dist_y))\n",
    "        dist_mat = dist.view(pred.size(0),-1,half-1)\n",
    "        \n",
    "        r_mag = torch.sqrt(torch.square(pos_x) + torch.square(pos_y))\n",
    "        \n",
    "        \n",
    "        #### Calculate interaction forces #####\n",
    "        \n",
    "        self.f_inter_x=(dist_x/dist)*(self.lambda1*(dist**self.power1)+self.lambda2*(dist**self.power2)+self.lambda3*(dist**self.power3)\\\n",
    "                                      +self.lambda4)\n",
    "        self.f_inter_y=(dist_y/dist)*(self.lambda1*(dist**self.power1)+self.lambda2*(dist**self.power2)+self.lambda3*(dist**self.power3)\\\n",
    "                                      +self.lambda4)\n",
    "        \n",
    "\n",
    "        f_agg_x = torch.zeros(self.row_num, half).to(device)\n",
    "        f_agg_y = torch.zeros(self.row_num, half).to(device)\n",
    "\n",
    "        f_agg_x = f_agg_x.scatter_add_(1, self.receivers.flatten().repeat(self.row_num,1).type(torch.int64), self.f_inter_x).to(device)\n",
    "        f_agg_y = f_agg_y.scatter_add_(1, self.receivers.flatten().repeat(self.row_num,1).type(torch.int64), self.f_inter_y).to(device)\n",
    "        \n",
    "        ######## Self propelled term #########        \n",
    "        \n",
    "        sp_x = 1*self.u[:,0:half]*(v0/self.u_mag-1)\n",
    "        sp_y = 1*self.u[:,half:]*(v0/self.u_mag-1)\n",
    "        \n",
    "        ode_x = self.accel[:,0:half]-sp_x-f_agg_x\n",
    "        ode_y = self.accel[:,half:]-sp_y-f_agg_y\n",
    "\n",
    "        self.loss_force = torch.sum(torch.square(ode_x)+torch.square(ode_y))/(pred.size(0)*half)\n",
    "        \n",
    "        #Loss from velocity\n",
    "        self.loss_vel_mag = loss_mse(self.u_mag[0,:],torch.tensor([v0], dtype=torch.float32).to(device))\n",
    "        \n",
    "        #### Set the data point for ground truth ####\n",
    "        self.data_pt = torch.arange(0, N_time, N_time//(N_time//10))\n",
    "        \n",
    "        \n",
    "        ######## Order parameter #########\n",
    "        r_mag_avg = torch.mean(r_mag, dim=1, keepdim=True)\n",
    "        \n",
    "        denom = radius*v0\n",
    "        ang_mom = torch.mean(pos_x*self.u[:,half:] - pos_y*self.u[:,0:half], dim=1, keepdim=True)\n",
    "        ang_mom_abs = torch.mean(torch.abs(pos_x*self.u[:,half:] - pos_y*self.u[:,0:half]), dim=1, keepdim=True)\n",
    "        order_para =  ang_mom/denom\n",
    "        order_para_abs = ang_mom_abs/denom\n",
    "        \n",
    "        \n",
    "        self.loss_ord_abs = loss_mse(order_para_abs[self.data_pt,:],\\\n",
    "                                     torch.tensor([1.], dtype=torch.float32).to(device))\n",
    "        self.loss_radius = loss_mse(r_mag_avg[self.data_pt,:], \\\n",
    "                                    torch.tensor([radius], dtype=torch.float32).to(device))\n",
    "        \n",
    "        loss = 1*self.loss_vel_mag + 5*self.loss_radius + 5*self.loss_ord_abs + 1*self.loss_force\n",
    "\n",
    "                  \n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "419055f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### indexing for interaction ############\n",
    "\n",
    "n_agents = 40\n",
    "\n",
    "senders=[]\n",
    "receivers=[]\n",
    "\n",
    "for i in range(n_agents):\n",
    "    for j in range(n_agents-1):\n",
    "        receivers.append([i])\n",
    "    for k in range(n_agents):\n",
    "        if k!=i:\n",
    "            senders.append([k])\n",
    "\n",
    "senders_G= torch.tensor(senders, dtype=torch.float32).to(device)  #index of the sender node for edge\n",
    "receivers_G= torch.tensor(receivers, dtype=torch.float32).to(device)  #index of the receiver node for edge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea9a9e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure():\n",
    "    model.train()\n",
    "    optimizer_LBFGS.zero_grad()\n",
    "    pred=model(t)\n",
    "    loss=model.loss_func(pred, r_a=r_a, r_b=r_b, v0=v0, tau=time_end-dt)\n",
    "\n",
    "    if torch.isfinite(loss).item:\n",
    "        loss.backward() \n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a58230af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([40])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\USER\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([11, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Stopped\n",
      "lambda1 = -1.358e-01 \n",
      "lambda2 = 4.574e-01 \n",
      "lambda3 = 8.822e-02 \n",
      "lambda4 = -4.157e-01\n",
      "power1 = -3.428e-01 \n",
      "power2 = -8.664e-02 \n",
      "power3 = -2.425e-01\n"
     ]
    }
   ],
   "source": [
    " \n",
    "#### define hyperparameter####\n",
    "\n",
    "dt = 0.05\n",
    "time_end = 5.0+dt\n",
    "v0 = 2\n",
    "epoch_adam=200\n",
    "epoch_LBFGS=1000\n",
    "patience=-21\n",
    "tolerance=1e-4\n",
    "\n",
    "##define input\n",
    "t = torch.arange(0, time_end-eps, dt, dtype=torch.float32)\n",
    "t = t.reshape(len(t),1).to(device)\n",
    "t.requires_grad=True\n",
    "out_num = n_agents * 2\n",
    "    \n",
    "r_avg = 4\n",
    "r_a, r_b = r_avg, r_avg\n",
    "\n",
    "retry_num = 100\n",
    "\n",
    "print(\"Training Started\")\n",
    "for ii in range(retry_num):\n",
    "    loss_value=[]\n",
    "    ##define model\n",
    "    model=PINN(input_num=1, output_num=out_num, receivers=receivers_G, senders=senders_G, radius = r_avg).to(device)\n",
    "\n",
    "    ## ADAM ##\n",
    "    for i in range(epoch_adam):\n",
    "        learning_rate = 0.001\n",
    "        optimizer_adam=torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        model.train()\n",
    "        optimizer_adam.zero_grad()\n",
    "\n",
    "        pred=model(t)\n",
    "        loss=model.loss_func(pred, r_a=r_a, r_b=r_b, v0=v0, tau=time_end-dt)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer_adam.step()\n",
    "        \n",
    "        loss_value.append(loss.item())\n",
    "        \n",
    "        ### Early Stop condition ###\n",
    "        if i>21:\n",
    "            if loss_value[-1] <= loss_value[-2] and abs(loss_value[-1]-np.mean(loss_value[patience:-1])) < tolerance:\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ##LBFGS ##\n",
    "    optimizer_LBFGS=torch.optim.LBFGS(model.parameters(), lr=0.1, max_iter=20, line_search_fn = 'strong_wolfe')\n",
    "\n",
    "    for i in range(epoch_LBFGS):\n",
    "\n",
    "        loss_prev = optimizer_LBFGS.step(closure)\n",
    "        if torch.isfinite(loss_prev) == False:\n",
    "            break\n",
    "        loss_value.append(loss_prev.item())\n",
    "        ### Early Stop condition ###\n",
    "        if i>21:\n",
    "            if loss_value[-1] <= loss_value[-2] and abs(loss_value[-1]-np.mean(loss_value[patience:-1])) < tolerance:\n",
    "                break\n",
    "                \n",
    "        \n",
    "    \n",
    "    ### Stopping Condition ####\n",
    "    if model.loss_ord_abs.item()<0.1 and model.loss_force.item()<0.1:\n",
    "        break\n",
    "\n",
    "print(\"Training Stopped\")        \n",
    "\n",
    "print(\"lambda1 = %.3e \\nlambda2 = %.3e \\nlambda3 = %.3e \\nlambda4 = %.3e\" \\\n",
    "      %(model.lambda1, model.lambda2, model.lambda3, model.lambda4))\n",
    "print(\"power1 = %.3e \\npower2 = %.3e \\npower3 = %.3e\" \\\n",
    "      %(model.power1, model.power2, model.power3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d607c4e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
